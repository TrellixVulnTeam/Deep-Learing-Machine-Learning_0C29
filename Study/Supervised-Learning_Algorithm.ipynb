{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e22200",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "<a href='https://ybdata-sci.tistory.com/19'>각 코드에 관한 설명</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15929e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "# print scatterplot\n",
    "mglearn.discrete_scatter(X[:,0], X[:, 1], y)\n",
    "plt.legend(['Class 0', 'Class 1'], loc=4)\n",
    "plt.xlabel('First Feature')\n",
    "plt.ylabel('Second Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70e281",
   "metadata": {},
   "source": [
    "less feature dataset: Low-dimension dataset <br>\n",
    "many feature dataset: High-dimension dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use load_breast_cancer function from scikit-learn\n",
    "# load Classification Dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print('cancer.keys(): \\n', cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15959f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('유방암 데이터의 형태: ', cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de115d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('클래스별 샘플 개수:\\n',\n",
    "     {n:v for n, v in zip(cancer.target_names, np.bincount(cancer.target))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc047105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('특성의 이름: \\n', cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Regression Dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print('데이터의 형태: ', boston.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfebd9",
   "metadata": {},
   "source": [
    "### k-최근접 이웃\n",
    "가장 가까운 훈련 데이터 포인트 하나를 최근접 이웃으로 찾아 예측하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354188b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=3)\n",
    "# 클래스가 다수인 데이터셋에도 같은 방법을 적용할 수 있음\n",
    "# 각 클래스에 속한 이웃이 몇 개인지 헤아려 가장 많은 클래스를 예측값으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dive dataset train set, test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model object\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993fb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('테스트 데이터 예측:', clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('테스트 세트 정확도: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57017430",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier 분석\n",
    "2차원 데이터셋이므로 가능한 모든 테스트 포인트의 예측을 XY 평면에 그릴 수 있음 <br>\n",
    "그리고 각 데이터 포인트가 속한 클래스에 따라 평면의 색을 칠함<br>\n",
    "클래스 0과 클래스 1로 지정한 영역으로 나뉘는 결정 경계(Decision boundary) 추출<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mglearn.datasets import make_forge\n",
    "x, y = make_forge()\n",
    "_, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "for i, ax in zip([1, 3, 9], axes.ravel()):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(x, y)\n",
    "    mglearn.plots.plot_2d_separator(knn, x, fill=True, eps=0.5, alpha=0.5, ax=ax)\n",
    "    mglearn.discrete_scatter(x[:, 0], x[:, 1], y=y, ax=ax)\n",
    "    ax.set_title('k={}'.format(i))\n",
    "    ax.set_xlabel('feature 0')\n",
    "    ax.set_ylabel('feature 1')\n",
    "\n",
    "axes[0].legend(loc=(0.01, 1.01))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfacfeb",
   "metadata": {},
   "source": [
    "이웃의 수를 늘릴수록 결정 경계는 부드러워짐 <br>\n",
    "부드러운 경계는 더 단순한 모델을 의미함<br>\n",
    "이웃을 적게 사용하면 모델의 복잡도가 높아자고 많이 사용하면 복잡도가 낮아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 복잡도와 일반화 사이의 관계를 입증\n",
    "# 유방암 데이터셋\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# 1에서 10까지 n_neighbors를 적용\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # 모델 생성\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # 훈련 세트 정확도 저장\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # 일반화 정확도 저장\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label='train set Accuracy')\n",
    "plt.plot(neighbors_settings, test_accuracy, label='test set Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cc08a",
   "metadata": {},
   "source": [
    "### k-최근접 이웃 회귀\n",
    "k-최근접 이웃 알고리즘은 회귀 분석에도 쓰임 <br>\n",
    "최근접 이웃을 한 개만 이용할 때 예측은 그냥 가장 가까운 이웃의 타깃 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b705b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c75b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d31830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split wave dataset by training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# make object by n_neighbors=3\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# Train model used by train set and target\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb66019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('테스트 세트 예측:\\n', reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812807b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('테스트 세트 R^2: {:.2f}'.format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a86ad",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor 분석\n",
    "1차원 데이터셋에 대해 가능한 모든 특성 값을 만들어 예측해볼 수 있음 <br>\n",
    "x측을 따라 많은 포인트를 생성해 테스트 데이터셋을 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# make 1,000 data point between -3 and 3\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # predict used by neighbor 1, 3, 9\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "    \n",
    "    ax.set_title(\n",
    "        '{} neighbor train score: {:.2f} test score: {:.2f}'.format(\n",
    "            n_neighbors, reg.score(X_train, y_train),\n",
    "            reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel('feature')\n",
    "    ax.set_ylabel('target')\n",
    "axes[0].legend(['model predict', 'train data/traget',\n",
    "             'test data/target'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d5be3",
   "metadata": {},
   "source": [
    "### 장단점과 매개변수\n",
    "KNeighbors 분류기에 중요한 매개변수는 두 개 <br>\n",
    "데이터 포인트 사이의 거리를 재는 방법과 이웃의 수 <br>\n",
    "실제로 이웃의 수는 3개나 5개 정도로 적을 때 잘 작동함 (기본적으로 유클리디안 거리 방식 사용)<br>\n",
    "k-NN의 장점은 ***이해하기 매우 쉬운 모델*** <br>\n",
    "특성의 수나 샘플의 수가 클 경우 예측이 느려짐 <br>\n",
    "또한 데이터의 전처리가 중요한 알고리즘 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5fcd9",
   "metadata": {},
   "source": [
    "## 선형 모델\n",
    "입력 특성에 대한 선형 함수를 만들어 예측을 수행 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f7414",
   "metadata": {},
   "source": [
    "### 회귀의 선형 모델\n",
    "w: 기울기 <br>\n",
    "b: 절편<br>\n",
    "예측값은 입력 특성에 w의 각 가중치를 곱해서 더한 가중치의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c11c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e46d0",
   "metadata": {},
   "source": [
    "기울기는 대략 0.4 <br>\n",
    "회귀를 위한 선형 모델은 특성이 하나일 땐 직선 두 개일 땐 평면 그 이상은 초평면(hyperplane) <br>\n",
    "선형 회귀는 데이터의 상세 정보를 모두 잃은 것처럼 보임 <br>\n",
    "특성이 많은 데이터셋이라면 훨씬 훌륭한 성능이 가능 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc06be",
   "metadata": {},
   "source": [
    "### 선형 회귀(최소제곱법)\n",
    "선형 회귀(linear regression) 또는 최소제곱법(OLS, ordinary least squres) <br>\n",
    "평균제곱오차(mean squared error)를 최소화하는 파라미터 w와 b를 찾음<br>\n",
    "평균제곱오차는 타깃 값의 차이를 제곱하여 더한 후 샘플의 개수로 나눈 것 <br>\n",
    "선형 회귀는 매개변수가 없는 것이 장점이지만, 그래서 모델의 복잡도를 제어할 수 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "# 기울기 파라미터 (w)는 가중치(weight) 또는 계수(coefficient)라고 하며 lr 객체의 coef_석상에 저장됨, 실수(float)값 하나\n",
    "# 편향(offset) 파라미터(b)는 intercept_속성에 저장, 각 입력 특성에 하나씩 대응되는 Numpy 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lr.ceof_: ', lr.coef_)\n",
    "print('lr.intercept_: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7aea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('훈련 세트 점수: {:.2f}'.format(lr.score(X_train, y_train)))\n",
    "print('테스트 세트 점수: {:.2f}'.format(lr.scor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430af1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086549f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
